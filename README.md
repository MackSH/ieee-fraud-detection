# D√©tection de Fraude - Projet IEEE-CIS Kaggle

Ce projet vise √† d√©velopper un mod√®le de machine learning capable d‚Äôidentifier des transactions frauduleuses √† partir de donn√©es issues du concours Kaggle IEEE-CIS Fraud Detection.  
Il simule les besoins r√©els d‚Äôune banque souhaitant r√©duire les pertes li√©es √† la fraude.


## Objectifs

- Analyser et comprendre les donn√©es de transactions.
- Cr√©er et comparer diff√©rents mod√®les de d√©tection de fraude.
- √âvaluer la performance selon des m√©triques adapt√©es (AUC, pr√©cision, rappel, F1).
- D√©montrer un pipeline reproductible pour une utilisation en contexte bancaire.


## Jeu de donn√©es

Les donn√©es proviennent du concours [IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection).  
Elles contiennent :
- Donn√©es transactionnelles : montants, horodatages, device, etc.
- Donn√©es client anonymis√©es : identifiants, caract√©ristiques d√©riv√©es.
- Variable cible : `isFraud` (1 = fraude, 0 = transaction normale).


## Organisation des notebooks

- `01_data_exploration.ipynb` ‚Üí Analyse exploratoire (EDA)
- `02_correlation_analysis
.ipynb` ‚Üí Nettoyage & cr√©ation de features
- `03_modeling_baseline.ipynb` ‚Üí Mod√®le de base



## Installation

Clonez le projet :
```bash
git clone https://github.com/tonpseudo/ieee-fraud-detection.git
cd ieee-fraud-detection

# Cr√©ez un environnement virtuel et activez-le
windows:
python -m venv venv
venv\Scripts\activate

MacOS/Linux:
python3 -m venv venv
source venv/bin/activate

Installez les d√©pendances :
pip install -r requirements.txt

Extraire les donnees:
python extract_data.py

Lancez l'api et le dashboard:
python API_&_ Dashboard/start_services.py
```

## Utilisation

Ex√©cutez les notebooks dans l‚Äôordre pour reproduire les r√©sultats :  
1. Exploration des donn√©es  
2. Analyse de corr√©lation
3. Mod√©lisation, Evaluation et Validation 


---



## M√©thodologie & R√©sultats

### Objectif du projet
L‚Äôobjectif de ce projet est de construire un mod√®le de **d√©tection de fraude sur les transactions bancaires** √† partir du jeu de donn√©es du concours **IEEE-CIS Fraud Detection**.  
Ce dataset est **hautement d√©s√©quilibr√©** (‚âà 96.5 % de transactions normales contre 3.5 % de transactions frauduleuses), ce qui rend la t√¢che de classification particuli√®rement complexe.

---

### M√©thodologie

#### Pr√©paration des donn√©es
- Nettoyage et suppression des colonnes inutiles.
- Transformation temporelle :
  ```python
  for i in range(1, 16):
      df["D" + str(i) + "n"] = df["D" + str(i)] - df["TransactionDT"] / (24*60*60)
    ```
- Encodage des variables cat√©gorielles par Label Encoding.
- Mise √† l‚Äô√©chelle (Min-Max Scaling) des variables num√©riques.
- Gestion du d√©s√©quilibre des classes gr√¢ce √† :
- scale_pos_weight dans XGBoost et CatBoost,
- class_weight dans LightGBM.


#### Entra√Ænement des mod√®les
Trois mod√®les ont √©t√© test√©s et compar√©s :

| Mod√®le       | Biblioth√®que | M√©thode d‚Äô√©quilibrage | Particularit√©                                             |
| ------------ | ------------ | --------------------- | --------------------------------------------------------- |
| **XGBoost**  | `xgboost`    | `scale_pos_weight`    | Rapide, robuste sur les features bruit√©es                 |
| **CatBoost** | `catboost`   | `scale_pos_weight`    | Excellente gestion automatique des features cat√©gorielles |
| **LightGBM** | `lightgbm`   | `class_weight`        | Tr√®s performant sur grands volumes de donn√©es             |

Tous les mod√®les ont √©t√© √©valu√©s sur la m√™me partition train/test √† l‚Äôaide de la ROC-AUC comme m√©trique principale.

#### √âvaluation des performances

| Mod√®le          |  ROC-AUC  | Pr√©cision fraude | Fausse alerte (FPR) | Vraie d√©tection (TPR) |
| :-------------- | :-------: | :--------------: | :-----------------: | :-------------------: |
| ü•á **XGBoost**  | **0.949** |       Bonne      |        Faible       |         √âlev√©e        |
| ü•à **CatBoost** |   0.937   |    Tr√®s stable   |       Moyenne       |         √âlev√©e        |
| ü•â **LightGBM** |   0.921   |     Correcte     |  Un peu plus √©lev√©e |        Moyenne        |


#### Matrices de confusion (r√©sum√©)

Matrices de confusion (r√©sum√©)


---
### S√©lection du mod√®le final

Le mod√®le XGBoost a √©t√© retenu comme mod√®le final pour plusieurs raisons :

- Meilleur score ROC-AUC (‚âà 0.95).
- Bon compromis entre sensibilit√© (d√©tection de fraudes) et sp√©cificit√© (peu de faux positifs).
- Bonne vitesse d‚Äôinf√©rence, id√©ale pour un d√©ploiement en API temps r√©el.

Le mod√®le final a √©t√© sauvegard√© en format .joblib :
```python
joblib.dump(best_model, "best_model.joblib")
```

.


## ‚ö†Ô∏è Limites et pistes d'am√©lioration

- Donn√©es anonymis√©es ‚Üí certaines variables difficiles √† interpr√©ter.
- Pas d‚Äôacc√®s aux donn√©es en temps r√©el.
- Possibilit√© d‚Äôam√©liorer avec des mod√®les deep learning (Transformers, TabNet).
- Besoin d‚Äôun monitoring pour d√©tecter le drift des donn√©es.


## Auteurs

Projet r√©alis√© par Mackenson JOSEPH et Abdielson LYVERT dans le cadre d‚Äôun bootcamp de Data Science.  
Bas√© sur le dataset IEEE-CIS Kaggle.