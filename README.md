# D√©tection de Fraude - Projet IEEE-CIS Kaggle

Ce projet vise √† d√©velopper un mod√®le de machine learning capable d‚Äôidentifier des transactions frauduleuses √† partir de donn√©es issues du concours Kaggle IEEE-CIS Fraud Detection.  
Il simule les besoins r√©els d‚Äôune banque souhaitant r√©duire les pertes li√©es √† la fraude.


## Objectifs

- Analyser et comprendre les donn√©es de transactions.
- Cr√©er et comparer diff√©rents mod√®les de d√©tection de fraude.
- √âvaluer la performance selon des m√©triques adapt√©es (AUC, pr√©cision, rappel, F1).
- D√©montrer un pipeline reproductible pour une utilisation en contexte bancaire.


## Jeu de donn√©es

Les donn√©es proviennent du concours [IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection).  
Elles contiennent :
- Donn√©es transactionnelles : montants, horodatages, device, etc.
- Donn√©es client anonymis√©es : identifiants, caract√©ristiques d√©riv√©es.
- Variable cible : `isFraud` (1 = fraude, 0 = transaction normale).


## Organisation des notebooks

- `01_data_exploration.ipynb` ‚Üí Analyse exploratoire (EDA)
- `02_feature_engineering.ipynb` ‚Üí Nettoyage & cr√©ation de features
- `03_modeling_baseline.ipynb` ‚Üí Mod√®le de base
- `04_modeling_advanced.ipynb` ‚Üí Mod√®les avanc√©s & tuning
- `05_evaluation_and_validation.ipynb` ‚Üí Comparaison & validation
- `06_deployment_preparation.ipynb` ‚Üí Export & pipeline
- `07_reporting.ipynb` ‚Üí R√©sum√© ex√©cutif & visualisations


## Installation

Clonez le projet :
```bash
git clone https://github.com/tonpseudo/ieee-fraud-detection.git

cd ieee-fraud-detection

pip install -r requirements.txt
```



---


## Utilisation

Ex√©cutez les notebooks dans l‚Äôordre pour reproduire les r√©sultats :  
1. Exploration des donn√©es  
2. Feature engineering  
3. Mod√©lisation  
4. √âvaluation  

Vous pouvez √©galement lancer le pipeline d‚Äôentra√Ænement complet : python train_pipeline.py


## R√©sultats

- Mod√®le retenu : LightGBM + features m√©tiers
- AUC : 0.922
- Pr√©cision : 89%
- Rappel : 76%

üëâ Explicabilit√© : analyse des features importantes avec SHAP.


## ‚ö†Ô∏è Limites et pistes d'am√©lioration

- Donn√©es anonymis√©es ‚Üí certaines variables difficiles √† interpr√©ter.
- Pas d‚Äôacc√®s aux donn√©es en temps r√©el.
- Possibilit√© d‚Äôam√©liorer avec des mod√®les deep learning (Transformers, TabNet).
- Besoin d‚Äôun monitoring pour d√©tecter le drift des donn√©es.


## Auteurs

Projet r√©alis√© par Mackenson JOSEPH et Abdielson LYVERT dans le cadre d‚Äôun bootcamp de Data Science.  
Bas√© sur le dataset IEEE-CIS Kaggle.